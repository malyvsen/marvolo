{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats computation\n",
    "\n",
    "This notebook computes some statistics to help estimate the probability of a name occuring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from marvolo import atomize, join_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_name = \"names-male\"\n",
    "names_df = pd.read_csv(f\"{csv_name}.csv\").dropna()\n",
    "names_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = names_df[\"Nazwisko aktualne\" if csv_name.startswith(\"surname\") else \"IMIĘ PIERWSZE\"]\n",
    "name_counts = names_df[\"Liczba\" if csv_name.startswith(\"surname\") else \"LICZBA WYSTĄPIEŃ\"]\n",
    "name_counts[names.str.endswith(\"SKI\")].sum() / name_counts.sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byte pair encoding\n",
    "\n",
    "To efficiently find popular groups of characters, we use byte pair encoding on the names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_group_pairs(grouped_name):\n",
    "    for first_group, second_group in zip(grouped_name[:-1], grouped_name[1:]):\n",
    "        yield first_group + second_group\n",
    "\n",
    "\n",
    "list(iterate_group_pairs(atomize(\"KOWALSKI\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularities(grouped_names, name_counts, name_to_iterable):\n",
    "    result = {}\n",
    "    for grouped_name, count in zip(grouped_names, name_counts):\n",
    "        for occurence in name_to_iterable(grouped_name):\n",
    "            if occurence not in result:\n",
    "                result[occurence] = 0\n",
    "            result[occurence] += count\n",
    "    return result\n",
    "\n",
    "\n",
    "popular_groups = []\n",
    "grouped_names = [atomize(name) for name in names]\n",
    "for i in trange(100 if csv_name.startswith(\"surname\") else 50):\n",
    "    group_pair_popularities = popularities(\n",
    "        grouped_names,\n",
    "        name_counts=name_counts,\n",
    "        name_to_iterable=iterate_group_pairs,\n",
    "    )\n",
    "    most_popular_group_pair = max(\n",
    "        group_pair_popularities.items(),\n",
    "        key=lambda key_value: key_value[1],\n",
    "    )[0]\n",
    "    grouped_names = [\n",
    "        join_groups(grouped_name, most_popular_group_pair)\n",
    "        for grouped_name in grouped_names\n",
    "    ]\n",
    "    popular_groups.append(most_popular_group_pair)\n",
    "\n",
    "popular_groups[:10]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability computation\n",
    "\n",
    "To be able to compute the probability of a name later, we need to compute a few probability distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probabilities(popularities):\n",
    "    total_popularity = sum(popularities.values())\n",
    "    return {\n",
    "        key: math.log(popularity) - math.log(total_popularity)\n",
    "        for key, popularity in popularities.items()\n",
    "    }\n",
    "\n",
    "\n",
    "log_group_probabilities = log_probabilities(\n",
    "    popularities(\n",
    "        grouped_names=grouped_names,\n",
    "        name_counts=name_counts,\n",
    "        name_to_iterable=lambda name: name,\n",
    "    )\n",
    ")\n",
    "log_group_probabilities[\"^\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pair_probabilities = log_probabilities(\n",
    "    popularities(\n",
    "        grouped_names,\n",
    "        name_counts=name_counts,\n",
    "        name_to_iterable=iterate_group_pairs,\n",
    "    ),\n",
    ")\n",
    "len(log_pair_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_length_probabilities = log_probabilities(\n",
    "    popularities(\n",
    "        grouped_names=grouped_names,\n",
    "        name_counts=name_counts,\n",
    "        name_to_iterable=lambda grouped_name: [len(grouped_name)],\n",
    "    )\n",
    ")\n",
    "log_length_probabilities[8]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"stats/{csv_name}.json\", \"w\") as file:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"popular_groups\": popular_groups,\n",
    "            \"log_group_probabilities\": log_group_probabilities,\n",
    "            \"log_pair_probabilities\": log_pair_probabilities,\n",
    "            \"log_length_probabilities\": log_length_probabilities,\n",
    "        },\n",
    "        file,\n",
    "        indent=4,\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
